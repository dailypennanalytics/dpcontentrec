{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/michellexiong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk; nltk.download('stopwords')\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import similarities\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data_lemmatized\n",
    "%store -r model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK Stopwords \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset as dataframe\n",
    "df = pd.read_csv(\"street.csv\")\n",
    "\n",
    "#Combine title, slug, and content\n",
    "df['all_text'] = df[\"title\"].map(str) + ' ' + df['slug'] + ' ' + df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to list of lyrics\n",
    "data = df.all_text.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to tokenize lyrics\n",
    "def text_to_words(text):\n",
    "    for article in text:\n",
    "         # simple_preprocess converts documents into list of lowercase tokens, deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(article), deacc=True))  \n",
    "        \n",
    "#create list of list of words in each song         \n",
    "data_words = list(text_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional- few important bigrams and trigrams found in lyrics data\n",
    "#Build bigram and trigram models - two or three words frequently occuring together in document\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) \n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100) \n",
    "\n",
    "#Faster way to access trigrams and bigrams\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "#define function for bigrams\n",
    "def make_bigrams(content):\n",
    "    return[bigram_mod[article] for article in content]\n",
    "\n",
    "#define function for trigrams\n",
    "def make_trigrams(content):\n",
    "    return[trigram_mod[bigram_mod[article]] for article in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    #create list with every word in a song if they are not stop word for every song in lyrics list\n",
    "    return [[word for word in simple_preprocess(str(article)) if word not in stop_words] for article in text]\n",
    "\n",
    "#define lemmatization function\n",
    "def lemmatization(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for entry in text:\n",
    "        #nlp object spacy \n",
    "        article = nlp(\" \".join(entry))\n",
    "        texts_out.append([word.lemma_ for word in article if word.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call stopwords function\n",
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_words_nostops[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional - call function to make bigrams for dataset\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call lemmatize function\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data_lemmatized' (list)\n"
     ]
    }
   ],
   "source": [
    "%store data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Dictionary for topic modelling which assigns unique id for each word in lyrics data\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "#create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "#Term document frequency, corpus is list of list of tuples in which word id x occurs y times in song\n",
    "corpus = [id2word.doc2bow(t) for t in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(corpus, num_features=len(id2word), num_best = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender (query):\n",
    "    recs = []\n",
    "    i = df.index[df['id'] == query].tolist()[0]\n",
    "    words = data_lemmatized[i]\n",
    "    query_vector = id2word.doc2bow(words)\n",
    "    sims = index[query_vector]\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_recs(sims):\n",
    "    count = 0\n",
    "    recs = []\n",
    "    for r in sims:\n",
    "        i = r[0]\n",
    "        article = df.iloc[i]['title'] + \" \" + str(r[1])\n",
    "        if article not in recs:\n",
    "            recs.append(article)\n",
    "            count += 1\n",
    "            if count == 10:\n",
    "                break                                                                     \n",
    "    pprint(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Oscars Once Again Prove Outdated and Irrelevant 1.0',\n",
      " \"Deconstructing Diversity in this Year's 'Best Director' Nominations \"\n",
      " '0.6139607429504395',\n",
      " \"The Oscars are a Man's World 0.5136854648590088\",\n",
      " 'Oscar Nominations: The Biggest Snubs and Surprises 0.5058308839797974',\n",
      " 'Oscars Firsts: Celebrating Women Behind the Camera 0.4797067940235138',\n",
      " \"Street's Predictions for the 91st Academy Awards  0.46004679799079895\",\n",
      " 'Oscars 2014: Five Biggest Snubs 0.44958004355430603',\n",
      " \"Charlize theron's golden globes 0.44917550683021545\",\n",
      " \"The Oscars' 'Best Popular Film' Award: Blurring the Lines Between Commercial \"\n",
      " 'and Artistic Success 0.43383675813674927',\n",
      " 'How to Make an Oscar–Winning Film 0.4062246084213257']\n"
     ]
    }
   ],
   "source": [
    "see_recs(recommender(37013))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frances Quinlan Comes Full Circle in Her Solo Debut 1.0',\n",
      " '10 Songs Instrumental to our Experiences  0.5275651216506958',\n",
      " 'Interviewing Waterparks Frontman Awsten Knight 0.4949963092803955',\n",
      " 'Street Writers Choose Their Desert Island Discs 0.48726117610931396',\n",
      " 'Queen of the Hill Meets the Hippest Cat in Town 0.4734741747379303',\n",
      " \"'Nation of Two' by Vance Joy Doesn't Hold Up 0.470693439245224\",\n",
      " 'You Should Know About: Cullen Omori 0.4648980498313904',\n",
      " 'And The Album Of The Year Is... 0.4648503065109253',\n",
      " 'Interview: Atlas Genius 0.4570596218109131',\n",
      " \"Mannequin Pussy Aren't What You Expect 0.45556217432022095\"]\n"
     ]
    }
   ],
   "source": [
    "see_recs(recommender(37011))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meet Tori Borlase: The UA Representative Who Organized the Philadelphia '\n",
      " 'Climate Strike 1.0000001192092896',\n",
      " 'Caution vs. Revolution: The Divide on Climate Change 0.4000192880630493',\n",
      " \"Don't Argue With Anish Welde, Penn's Top Novice Debater  0.3891429305076599\",\n",
      " 'Not Enough  0.37514394521713257',\n",
      " 'I Went Back to High School, and It Felt Like I Was Still at Penn  '\n",
      " '0.3673226833343506',\n",
      " 'Meet Natasha Menon, Your New UA President 0.3665757179260254',\n",
      " 'Ego of the Week: Connor Swords 0.3633180856704712',\n",
      " 'JMHH Awards: Students Breaking Wharton Stereotypes  0.36320754885673523',\n",
      " 'Penn 10: Krisna Maddy 0.36231887340545654',\n",
      " 'From the West Bank to West Philadelphia  0.36064159870147705']\n"
     ]
    }
   ],
   "source": [
    "see_recs(recommender(35967))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meet Tori Borlase: The UA Representative Who Organized the Philadelphia '\n",
      " 'Climate Strike 0.8200399875640869',\n",
      " 'Caution vs. Revolution: The Divide on Climate Change 0.27989792823791504',\n",
      " 'Ego of the Week: Connor Swords 0.23656034469604492',\n",
      " 'I Went Back to High School, and It Felt Like I Was Still at Penn  '\n",
      " '0.22411540150642395',\n",
      " \"Qu'est-ce Que C'est Chick-Lit? 0.2205362766981125\",\n",
      " 'Ego of the Week: Nicolas Garcia 0.2145242989063263',\n",
      " 'Not Enough  0.2085728794336319',\n",
      " \"Don't Argue With Anish Welde, Penn's Top Novice Debater  0.199131578207016\",\n",
      " 'Ego of the Week: Jordan Williams  0.19467931985855103',\n",
      " 'Ego of the Week: Nicholas Escobar 0.1915401965379715']\n"
     ]
    }
   ],
   "source": [
    "see_recs(tfidf_recommender(35967))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can Cakes and Sweaters Enact Political Change?',\n",
      " 'How Your Insta Feed Can Boost Your Self Esteem ',\n",
      " 'Open Studios Preview: Out in the Open with Nowhere to Hide',\n",
      " 'Art and Politics: An Introduction',\n",
      " 'The Best Ways to Eat Your Booze',\n",
      " 'The Insta–Famous Food Blogs of Penn You Need to Follow',\n",
      " \"Celebrate Women's History Month in Philadelphia\",\n",
      " \"What to Read After Finishing Michelle Obama's 'Becoming'\",\n",
      " \"Revisiting 'All The President’s' Men In Light of 'The Post'\",\n",
      " 'How to Spend Your Day in Old City']\n"
     ]
    }
   ],
   "source": [
    "see_recs(recommender(35451))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can Cakes and Sweaters Enact Political Change?',\n",
      " \"Celebrate Women's History Month in Philadelphia\",\n",
      " 'How Your Insta Feed Can Boost Your Self Esteem ',\n",
      " 'The Insta–Famous Food Blogs of Penn You Need to Follow',\n",
      " 'How to Prove You’re Open–Minded to That Facebook Friend You Haven’t Seen in '\n",
      " 'Five Years',\n",
      " 'Open Studios Preview: Out in the Open with Nowhere to Hide',\n",
      " 'The Best Ways to Eat Your Booze',\n",
      " 'How to Spend Your Day in Old City',\n",
      " 'Baked Girl: Five-Minute Mug Cakes',\n",
      " \"What to Read After Finishing Michelle Obama's 'Becoming'\"]\n"
     ]
    }
   ],
   "source": [
    "see_recs(tfidf_recommender(35451))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Overheards 11.17.16',\n",
      " 'Overheard at Penn: 03.17.2011',\n",
      " 'Overheards: 10.23.14',\n",
      " 'Overheard at Penn: 3.14.13',\n",
      " 'Best campus eatery to find a cute girl',\n",
      " 'SHOUTOUTS. Fall 2011',\n",
      " \"Is 'Tall Girl' Really that Bad?\",\n",
      " 'Word on the Street: Everybody Has a Story',\n",
      " 'OVERHEARDS 3.24.16',\n",
      " 'Overheard at Penn: 1.17.13']\n"
     ]
    }
   ],
   "source": [
    "see_recs(recommender(30372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Overheards 11.17.16 0.8232963681221008',\n",
      " 'Overheards: 10.23.14 0.2453722357749939',\n",
      " 'Overheard at Penn: 03.17.2011 0.22762887179851532',\n",
      " 'On Getting Cut 0.1869812160730362',\n",
      " 'An Open Letter to Sad Freshmen Girls 0.1767139732837677',\n",
      " 'Street Shout-Outs 0.1733660101890564',\n",
      " 'Shoutouts Fall 2006 0.1727592647075653',\n",
      " 'No Valentine, No Problem 0.17058919370174408',\n",
      " 'DO YOU HAVE AN ANONYMOUS ROMANCE-RELATED MESSAGE FOR ANYONE AT PENN? '\n",
      " '0.1669594943523407',\n",
      " 'On Getting Cut 0.16638025641441345']\n"
     ]
    }
   ],
   "source": [
    "see_recs(tfidf_recommender(30372))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_index = similarities.MatrixSimilarity(tfidf[corpus], num_features=len(id2word), num_best = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_recommender (query):\n",
    "    recs = []\n",
    "    i = df.index[df['id'] == query].tolist()[0]\n",
    "    words = data_lemmatized[i]\n",
    "    query_vector = id2word.doc2bow(words)\n",
    "    sims = tfidf_index[query_vector]\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Oscars Once Again Prove Outdated and Irrelevant',\n",
      " \"Deconstructing Diversity in this Year's 'Best Director' Nominations\",\n",
      " \"The Oscars are a Man's World\",\n",
      " 'Oscars Firsts: Celebrating Women Behind the Camera',\n",
      " 'Oscar Nominations: The Biggest Snubs and Surprises',\n",
      " 'Which Best Picture Nomination Speaks to Your Soul?',\n",
      " 'Is the \"Oscar Curse\" Real? ',\n",
      " \"The Oscars' 'Best Popular Film' Award: Blurring the Lines Between Commercial \"\n",
      " 'and Artistic Success',\n",
      " \"Charlize theron's golden globes\",\n",
      " 'How to Make an Oscar–Winning Film']\n"
     ]
    }
   ],
   "source": [
    "see_recs(tfidf_recommender(37013))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build LDA Model with ten topics\n",
    "lda_model50 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=50, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'lda_model50' (LdaModel)\n"
     ]
    }
   ],
   "source": [
    "%store lda_model50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r lda_model50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model = CoherenceModel(model=lda_model50, texts=data_lemmatized, dictionary=id2word, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.4861981110531002\n"
     ]
    }
   ],
   "source": [
    "coherence = coherence_model.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32,\n",
      "  '0.094*\"stewart\" + 0.076*\"army\" + 0.069*\"ica\" + 0.055*\"carter\" + '\n",
      "  '0.040*\"klein\" + 0.031*\"leo\" + 0.021*\"laboratory\" + 0.021*\"decay\" + '\n",
      "  '0.013*\"summary\" + 0.005*\"winding\"'),\n",
      " (20,\n",
      "  '0.192*\"celebrity\" + 0.144*\"lip\" + 0.082*\"makeup\" + 0.069*\"catholic\" + '\n",
      "  '0.024*\"cosmetic\" + 0.008*\"appliance\" + 0.004*\"halo\" + 0.000*\"warmup\" + '\n",
      "  '0.000*\"mesoamerican\" + 0.000*\"perineum\"'),\n",
      " (28,\n",
      "  '0.118*\"toy\" + 0.077*\"mexico\" + 0.074*\"marathon\" + 0.065*\"sincere\" + '\n",
      "  '0.045*\"neil\" + 0.042*\"maggie\" + 0.037*\"reunion\" + 0.035*\"ian\" + '\n",
      "  '0.029*\"lawn\" + 0.028*\"down\"'),\n",
      " (44,\n",
      "  '0.182*\"web\" + 0.130*\"lisa\" + 0.076*\"ipod\" + 0.051*\"beyonce\" + 0.048*\"mic\" + '\n",
      "  '0.045*\"essential\" + 0.039*\"poet\" + 0.016*\"regain\" + 0.011*\"subversive\" + '\n",
      "  '0.009*\"proactive\"'),\n",
      " (0,\n",
      "  '0.108*\"butter\" + 0.085*\"peanut\" + 0.072*\"veteran\" + 0.051*\"geek\" + '\n",
      "  '0.032*\"pc\" + 0.031*\"hannah\" + 0.028*\"tang\" + 0.023*\"caroline\" + '\n",
      "  '0.021*\"perry\" + 0.018*\"eating\"'),\n",
      " (48,\n",
      "  '0.181*\"creek\" + 0.137*\"skin\" + 0.127*\"france\" + 0.062*\"establishment\" + '\n",
      "  '0.047*\"dec\" + 0.023*\"beauty\" + 0.022*\"diy\" + 0.021*\"airplane\" + '\n",
      "  '0.017*\"convenience\" + 0.015*\"bronze\"'),\n",
      " (42,\n",
      "  '0.127*\"peter\" + 0.066*\"mile\" + 0.056*\"robot\" + 0.049*\"noah\" + 0.041*\"amy\" + '\n",
      "  '0.024*\"goofy\" + 0.022*\"fuzzy\" + 0.022*\"brook\" + 0.019*\"squad\" + '\n",
      "  '0.018*\"imaginary\"'),\n",
      " (49,\n",
      "  '0.080*\"moon\" + 0.078*\"kevin\" + 0.061*\"thief\" + 0.046*\"shred\" + '\n",
      "  '0.045*\"blank\" + 0.038*\"map\" + 0.036*\"curtis\" + 0.027*\"mode\" + '\n",
      "  '0.025*\"polished\" + 0.023*\"victorian\"'),\n",
      " (17,\n",
      "  '0.103*\"holiday\" + 0.101*\"halloween\" + 0.081*\"oct\" + 0.057*\"christmas\" + '\n",
      "  '0.050*\"nov\" + 0.045*\"feb\" + 0.044*\"independence\" + 0.043*\"jan\" + 0.034*\"pm\" '\n",
      "  '+ 0.023*\"lantern\"'),\n",
      " (1,\n",
      "  '0.134*\"rachel\" + 0.130*\"smith\" + 0.129*\"steve\" + 0.041*\"elizabeth\" + '\n",
      "  '0.030*\"christopher\" + 0.028*\"anna\" + 0.028*\"sketch\" + 0.026*\"blast\" + '\n",
      "  '0.024*\"oliver\" + 0.023*\"renowned\"'),\n",
      " (13,\n",
      "  '0.038*\"food\" + 0.024*\"restaurant\" + 0.019*\"menu\" + 0.016*\"meal\" + '\n",
      "  '0.014*\"cheese\" + 0.014*\"serve\" + 0.013*\"chicken\" + 0.013*\"dish\" + '\n",
      "  '0.010*\"eat\" + 0.010*\"fresh\"'),\n",
      " (22,\n",
      "  '0.060*\"penn\" + 0.043*\"student\" + 0.024*\"say\" + 0.019*\"school\" + '\n",
      "  '0.016*\"year\" + 0.015*\"college\" + 0.013*\"class\" + 0.013*\"group\" + '\n",
      "  '0.012*\"study\" + 0.011*\"community\"'),\n",
      " (35,\n",
      "  '0.022*\"family\" + 0.021*\"life\" + 0.020*\"story\" + 0.019*\"american\" + '\n",
      "  '0.018*\"man\" + 0.018*\"david\" + 0.018*\"child\" + 0.014*\"war\" + 0.012*\"live\" + '\n",
      "  '0.012*\"father\"'),\n",
      " (14,\n",
      "  '0.021*\"black\" + 0.019*\"white\" + 0.014*\"style\" + 0.014*\"wear\" + 0.012*\"look\" '\n",
      "  '+ 0.011*\"eye\" + 0.011*\"shirt\" + 0.009*\"dress\" + 0.009*\"color\" + '\n",
      "  '0.008*\"face\"'),\n",
      " (47,\n",
      "  '0.033*\"girl\" + 0.033*\"love\" + 0.030*\"get\" + 0.026*\"good\" + 0.026*\"guy\" + '\n",
      "  '0.024*\"boy\" + 0.021*\"know\" + 0.017*\"sex\" + 0.016*\"friend\" + 0.013*\"hot\"'),\n",
      " (25,\n",
      "  '0.018*\"night\" + 0.016*\"house\" + 0.015*\"place\" + 0.014*\"look\" + 0.014*\"bar\" '\n",
      "  '+ 0.013*\"room\" + 0.012*\"sit\" + 0.012*\"beer\" + 0.011*\"sun\" + 0.010*\"line\"'),\n",
      " (43,\n",
      "  '0.018*\"new\" + 0.017*\"year\" + 0.016*\"play\" + 0.016*\"game\" + 0.011*\"big\" + '\n",
      "  '0.010*\"last\" + 0.010*\"name\" + 0.010*\"man\" + 0.008*\"team\" + 0.008*\"rare\"'),\n",
      " (41,\n",
      "  '0.026*\"day\" + 0.018*\"time\" + 0.016*\"take\" + 0.014*\"week\" + 0.014*\"leave\" + '\n",
      "  '0.012*\"get\" + 0.009*\"home\" + 0.009*\"back\" + 0.009*\"go\" + 0.008*\"need\"'),\n",
      " (12,\n",
      "  '0.015*\"make\" + 0.012*\"new\" + 0.012*\"seem\" + 0.011*\"however\" + 0.011*\"may\" + '\n",
      "  '0.010*\"first\" + 0.009*\"well\" + 0.008*\"many\" + 0.008*\"create\" + '\n",
      "  '0.007*\"also\"'),\n",
      " (40,\n",
      "  '0.027*\"go\" + 0.024*\"say\" + 0.022*\"think\" + 0.021*\"get\" + 0.021*\"people\" + '\n",
      "  '0.021*\"know\" + 0.018*\"make\" + 0.018*\"really\" + 0.018*\"would\" + '\n",
      "  '0.016*\"want\"')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "/anaconda3/lib/python3.7/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "/anaconda3/lib/python3.7/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-65adee9db252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcoherence_model_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda_model50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcoherence_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoherence_model_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nCoherence Score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_lda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \"\"\"\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mconfirmed_measures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence_per_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_measures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfirmed_measures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence_per_topic\u001b[0;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normalize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoherence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c_npmi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmented_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accumulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maggregate_measures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_coherences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(segmented_topics, accumulator, topics, measure, gamma, with_std, with_support)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0msegment_sims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_star\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mw_prime_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mw_star_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0msegment_sims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cossim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_prime_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_star_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_context_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_context_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_word_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_word_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py\u001b[0m in \u001b[0;36mcompute_context_vector\u001b[0;34m(self, segment_word_ids, topic_word_ids)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_vector_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontext_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_word_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_word_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_vector_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontext_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py\u001b[0m in \u001b[0;36m_make_seg\u001b[0;34m(self, segment_word_ids, topic_word_ids)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_word_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__iter__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0msegment_word_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msegment_word_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized lil_matrix constructor usage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Print the Keywords in the 10 topics\n",
    "pprint(lda_model50.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.5002622792059759\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model50, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coherence_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to export topics as csv with keywords displayed incolumns \n",
    "def topics_to_df(model_topics):\n",
    "    top_index = []\n",
    "    keywords = []\n",
    "    for top, words in model_topics:\n",
    "        top_index.append(top)\n",
    "        keywords_separated = gensim.utils.simple_preprocess(words)\n",
    "        keywords.append(keywords_separated)\n",
    "    df_topics = pd.DataFrame(keywords)\n",
    "    df_topics = df_topics.transpose()\n",
    "    df_topics.columns = top_index\n",
    "    return df_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics10_df = topics_to_df(topics10)\n",
    "#topics10_df.to_csv('lyrics_ldamodel_10', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'lda_model40' (LdaModel)\n"
     ]
    }
   ],
   "source": [
    "#build LDA model 40 topics\n",
    "lda_model40 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=40, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_40 = topics_to_df(lda_model40.print_topics(num_topics=40, num_words=20))\n",
    "#lda_40.to_csv('lda40_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build LDA model 20 topics\n",
    "lda_model20 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "lda_20 = topics_to_df(lda_model20.print_topics(num_topics=20, num_words=20))\n",
    "#lda_20.to_csv('lda20_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'lda_model20' (LdaModel)\n"
     ]
    }
   ],
   "source": [
    "#store desired topic models to be used in next steps\n",
    "%store lda_model10\n",
    "%store lda_model40\n",
    "%store lda_model20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.4099813070531555\n",
      "\n",
      "Coherence Score:  0.39791162285705894\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model10.log_perplexity(corpus))  #lower the better.\n",
    "\n",
    "# Compute Coherence Score between zero and one higher the better\n",
    "coherence_model_lda = CoherenceModel(model=lda_model10, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create models with different number of topics and compute coherence, takes some time\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=False)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to generate list of models- set start, step and limit\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=10, limit=100, step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5085940577923722,\n",
       " 0.5268261101848211,\n",
       " 0.5170557519650683,\n",
       " 0.5076504914960591,\n",
       " 0.4905865017610599,\n",
       " 0.4811363186903156,\n",
       " 0.49117589638704723,\n",
       " 0.4731400427598802,\n",
       " 0.48352880760582295,\n",
       " 0.49405675153989365,\n",
       " 0.46180709007441967,\n",
       " 0.47153943278608235,\n",
       " 0.47290154854168903,\n",
       " 0.448053443835022,\n",
       " 0.46565254835150577,\n",
       " 0.4610292150405999,\n",
       " 0.4832309098903623,\n",
       " 0.4491806070073582]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_list' (list)\n"
     ]
    }
   ],
   "source": [
    "#store for future use\n",
    "%store model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VPW5+PHPk30hK0mAbIR9TwgEBGsV9x2rUgWtS3tv++tt1Vpte+1mq7a9drFqW7291m5aZXHHBam7rQsQIIGEHYQkQCAkJCwh+/P7YyYYQ5KZJHMyk+R5v17zMufM95x5Mg7z5Hy/5/t8RVUxxhhjuhLk7wCMMcYEPksWxhhjPLJkYYwxxiNLFsYYYzyyZGGMMcYjSxbGGGM8smRhjDHGI0sWxhhjPHI0WYjIRSKyVUR2iMhdHTx/s4hUiEiB+/Gf7v0jRWSte1+xiHzdyTiNMcZ0TZyawS0iwcA24HygDFgDLFLVTW3a3Azkqeot7Y4Nc8dWLyJDgCLgdFXd19nrJSUlaVZWls9/D2OMGcjWrl17SFWTPbULcTCG2cAOVd0FICJLgCuATV0eBahqQ5vNcLy4AsrKyiI/P7+HoRpjzOAkInu8aedkN1QaUNpmu8y9r72rRWSDiDwrIhmtO0UkQ0Q2uM/xy46uKkTkayKSLyL5FRUVvo7fGGOMm5PJQjrY177P62UgS1WzgTeBv59sqFrq3j8WuElEhp1yMtXHVDVPVfOSkz1eRRljjOkhJ5NFGZDRZjsd+MzVgapWqmq9e/NPwMz2J3FfURQDn3coTmOMMR44OWaxBhgnIqOAvcBC4Lq2DURkhKrud2/OBza796cDlap6QkQSgM8Bv3UwVmOM6ZXGxkbKysqoq6vzdygdioiIID09ndDQ0B4d71iyUNUmEbkFWAkEA39R1WIRuRfIV9XlwG0iMh9oAqqAm92HTwIeEBHF1Z31G1Xd6FSsxhjTW2VlZcTExJCVlYVIR73w/qOqVFZWUlZWxqhRo3p0DievLFDV14DX2u27u83P3we+38FxbwDZTsZmjDG+VFdXF5CJAkBEGDp0KL25EchmcBtjjI8EYqJo1dvYLFn4SHOL8uL6vRypa/R3KMYY43OWLHxkRdF+bl9awJ3LCrF1zY0xA40lCx9ZuqaU0GDhjU0HePJjryZEGmNMv2HJwgdKq2r51/ZDfPPssZw9IZmfvbqZTfuO+DssY8wg88QTT5CdnU1OTg433HCDT8/t6N1Qg8Uz+aWIwDV5GdwwZyQXP/wvbl28jpdvPYOoMHuLjRls7nm52Od/ME5OjeUnl0/p9Pni4mJ+/vOf88EHH5CUlERVVZVPX9+uLHqpqbmFZfllnDU+mdT4SIYOCeeha6ez69Bx7lnusWaiMcb4xNtvv82CBQtISkoCIDEx0afntz97e+n97RWUH6njp/Mnn9x3+tgkvjFvDI+8s5MzxiVxeU6qHyM0xvS1rq4AnKKqjt66a1cWvbRkdSlJQ8I4Z+Jn6xzeft54ZmTG84PnN1JaVeun6Iwxg8W5557LsmXLqKysBLBuqEBy8Ggdb205yNUz0wkL+exbGRocxMMLc0Hg1sXraWxu8VOUxpjBYMqUKfzwhz/krLPOIicnhzvuuMOn57dk0QvPrd1Lc4tybV5Gh89nJEZx/1XZFJRW89s3tvVxdMaYweamm26iqKiIwsJC/va3v/n03JYsekhVWbqmhNmjEhmdPKTTdpdmj2DR7Az++N5O/r39UB9GaIwxvmPJooc+3lXF7spaFs7q+Kqirbsvm8LY5CF8e1kBh47Ve2xvjDGBxpJFDy1dU0JMRAgXTx3hsW1kWDC/vy6XIycauXNZIS0tVg7EmIEokEv99DY2SxY9UFPbyGtF5XxhehqRYcFeHTNxeCw/umwy722r4M///sThCI0xfS0iIoLKysqATBit61lERET0+Bw2z6IHXizYS0NTCwtne+6CautLp2Xy7+0V/GrlFk4bnUh2erxDERpj+lp6ejplZWW9WjPCSa0r5fWUo8lCRC4CHsa1Ut7jqnp/u+dvBn6Na9lVgD+o6uMiMh34XyAWaAZ+rqpLnYzVW6rK4tUlTEuLY0pqXLeOFRF+eXU2lzz8L25dvJ5Xbj2DmIieLXFojAksoaGhPV6Frj9wrBtKRIKBR4CLgcnAIhGZ3EHTpao63f143L2vFrhRVacAFwEPiUhA/Bm+oayGLeVHudaLge2OxEeF8fCiXEqravnxi0UBeclqjDHtOTlmMRvYoaq7VLUBWAJc4c2BqrpNVbe7f94HHASSHYu0G5asKSUiNIj503tewmNWViK3nzeeFwv28dy6vZ4PMMYYP3MyWaQBpW22y9z72rtaRDaIyLMicsqf6yIyGwgDdnbw3NdEJF9E8vuin/B4fRPLC/Zy6bRUYnvZffTNs8cyZ3Qid79UxK6KYz6K0BhjnOFksuioolX7PpeXgSxVzQbeBP7+mROIjACeBL6sqqfUy1DVx1Q1T1XzkpOdv/B4deN+jjc0d3tguyPBQcJD1+YSHhLErYvXU9/U7IMIjTHGGU4mizKg7bdqOrCvbQNVrVTV1llqfwJmtj4nIrHAq8CPVPVjB+P02tI1pYxJjiZvZIJPzjc8LoJfL8iheN8R7l+xxSfnNMYYJziZLNYA40RklIiEAQuB5W0buK8cWs0HNrv3hwEvAE+o6jMOxui1bQeOsnbPYRbOyvRpGeDzJg/j5tOz+OsHu3lr8wGfndcYY3zJsWShqk3ALcBKXElgmaoWi8i9IjLf3ew2ESkWkULgNuBm9/5rgDOBm0WkwP2Y7lSs3mhdY/vKGR0Nu/TOXRdPZNKIWL7zTCHlNXU+P78xxvSWDJRbN/Py8jQ/P9+Rc9c3NTPnF28xd8xQHr1+pucDemBnxTEu+92/ycmI46n/nENwkHOLmBhjTCsRWauqeZ7aWbkPL7yx6QCHaxu5dlamY68xJnkI91wxhY93VfHoOzscex1jjOkJSxZeWLqmlLT4SD4/NsnR1/nizHTm56Ty4JvbWP2Jb1e5MsaY3rBk4UFpVS3/2n6Ia/IyCHK4a0hE+PmVU8lMjOLWxeusnLkxJmBYsvBgWX4pIvDFvJ4X4OqOmIhQHr1+JodrG7l9SQHNVs7cGBMALFl0oam5hWfyyzhrfDKp8ZF99rqTU2O5d/4U/r3jEL9/e3ufva4xxnTGkkUX3t9eQfmROq9Ww/O1a2dlcFVuGg+/td2WYzXG+J0liy4sWV1K0pAwzpk4rM9fW0T42ZVTGZs8hG8tWc+BIzb/whjjP5YsOnHwaB1vbTnI1TPTCQvxz9sUFRbCo9fPoLahmVufXk9T8ynlsYwxpk9YsujEs2vLaG5Rrs3r+y6otsYNi+EXV01l9e4qHnhjm19jMcYMXpYsOqCqLF1TyuxRiYxOHuLvcLgyN51FszP533d38vYWqx9ljOl7liw68PGuKvZU1vplYLszP7l8MpNHxPLtpYWUHa71dzjGmEHGkkUHlq4pISYihIunjvDcuI9EhAbz6PUzaG5Rvvn0ehqabPzCGNN3LFm0U1PbyGtF5XxhehqRYcH+DuczspKi+dWCbApLq/mfFZv9HY4xZhCxZNHOC+vLaGhq8clqeE64ZNqIk+tfrNi439/hGGMGCUsWbagqS9aUMi0tjimpcf4Op1M/uGQSORnxfO/ZDew+dNzf4RhjBgFLFm1sKKthS/lRrg2gge2OhIUE8ch1uQQFCd94ah11jbZ+tzHGWY4mCxG5SES2isgOEbmrg+dvFpGKNqvh/Web514XkWoRecXJGNtasqaUiNAg5k9P7auX7LH0hCh+e00Om/Yf4Z6XN/k7HGPMAOdYshCRYOAR4GJgMrBIRCZ30HSpqk53Px5vs//XwA1Oxdfe8fomlhfs5dJpqcRGhPbVy/bKuZOG8fWzxrB4dQkvrC/zdzjGmAHMySuL2cAOVd2lqg3AEuAKbw9W1beAo04F196rG/dzvKGZRQE6sN2Z71wwntlZifzg+SK2H+izt8sYM8g4mSzSgNI222Xufe1dLSIbRORZEenWN7WIfE1E8kUkv6KiojexsmR1CWOSo5k5MqFX5+lrIcFB/G5RLlFhwXzjqXXUNjT5OyRjzADkZLLoaFm59iv5vAxkqWo28Cbw9+68gKo+pqp5qpqXnJzcwzBh24GjrCupZuGsTEScXQ3PCcPjInh4YS47Ko7xoxeKULUFk4wxvuVksigD2l4ppAP72jZQ1UpVbV079E/ATAfj6dTSNaWEBgtXzujowqd/OGNcEt86dxzPr9/LsvxSzwcYY0w3OJks1gDjRGSUiIQBC4HlbRuISNt6GvOBPp+WXN/UzPPryjh/8jCShoT39cv71K3njOOMsUnc/VIxm/Yd8Xc4xpgBxLFkoapNwC3ASlxJYJmqFovIvSIy393sNhEpFpFC4Dbg5tbjReRfwDPAuSJSJiIXOhFn5bEGJqfGsnBWphOn71PBQcJDC6cTFxnKN55ay9G6Rn+HZIwZIGSg9G/n5eVpfn6+v8MICKt2VXLd46u4aMpw/nBdbr8chzHG9A0RWauqeZ7a2QzuAei00UO54/zxvLpxPx/vqvJ3OMaYAcCSxQD1lc+NIi4ylCc/3u3vUIwxA4AliwEqMiyYa/LSWVl8gPKaOn+HY4zp5yxZDGBfmjOSFlWeXl3i71CMMf2cJYsBbOTQaM4an8zi1SW2sp4xplcsWQxwN84dScXRelYWl/s7FGNMP2bJYoA7a3wKGYmRPPnRHn+HYozpxyxZDHDBQcKXThvJ6t1VbCm3Wd3GmJ6xZDEIXJOXQXhIEE/Y1YUxpocsWQwCCdFhXJ6Tyovr93LESoAYY3rAq2QhIpEiMsHpYIxzbpqbRW1DM8+ttRX1jDHd5zFZiMjlQAHwunt7uogs7/ooE2impccxPSOeJz/eY+tdGGO6zZsri5/iWiK1GkBVC4As50IyTrlx7kh2VRzngx2V/g7FGNPPeJMsmlS1xvFIjOMumTaCxOgwnvhot79DMcb0M94kiyIRuQ4IFpFxIvJ74EOH4zIOiAgN5tpZGby5+QB7q0/4OxxjTD/iTbK4FZgC1ANPAzXA7U4GZZxz/WmuRZ6eXmW30RpjvNdlshCRYOAeVf2hqs5yP36kql6VMRWRi0Rkq4jsEJG7Onj+ZhGpEJEC9+M/2zx3k4hsdz9u6vZvZjqUnhDFOROHsWR1KfVNzf4OxxjTT3SZLFS1GZjZkxO7E80jwMXAZGCRiEzuoOlSVZ3ufjzuPjYR+AlwGq7B9Z+ISEJP4jCnunHuSCqPN7Bio9WLMsZ4x5tuqPUislxEbhCRq1ofXhw3G9ihqrtUtQFYAlzhZVwXAm+oapWqHgbeAC7y8ljjwRljkxiVFG0D3cYYr3mTLBKBSuAc4HL34zIvjksDSttsl7n3tXe1iGwQkWdFJKObx5oeCAoSvjRnJOtKqinaaze6GWM885gsVPXLHTy+4sW5paPTtdt+GchS1WzgTeDv3TgWEfmaiOSLSH5FRYUXIZlWC2amExkabNVojTFe8WYGd7qIvCAiB0XkgIg8JyLpXpy7DMhos50O7GvbQFUrVbXevfknPh0f8Xis+/jHVDVPVfOSk5O9CMm0iosM5Qu5qbxUuJeaWqsXZYzpmjfdUH8FlgOpuLqCXnbv82QNME5ERolIGLDQfZ6TRGREm835wGb3zyuBC0QkwT2wfYF7n/GhG+ZkUdfYwjNrSz03NsYMat4ki2RV/auqNrkffwM8/hmvqk3ALbi+5DcDy1S1WETuFZH57ma3iUixiBQCtwE3u4+tAu7DlXDWAPe69xkfmpwaS97IBJ78eA8tLVYvyhjTOW+SxSER+ZKIBLsfX8I14O2Rqr6mquNVdYyq/ty9725VXe7++fuqOkVVc1T1bFXd0ubYv6jqWPfDmysZ0wM3zB3Jnspa3t9uYz7GmM55kyy+AlwDlAP7gQXufWYAuHjqCJKGhNtAtzGmSyGeGqhqCa7xBDMAhYUEsWh2Bn94ZwelVbVkJEb5OyRjTADy5m6ov4tIfJvtBBH5i7Nhmb503WmZBInwD6sXZYzphDfdUNmqWt264Z5RnetcSKavjYiL5PxJw1i2ppS6RqsXZYw5lTfJIqhtXSZ33SaP3Vemf7lx7kgO1zbycuEp01mMMcarZPEA8KGI3Cci9+Fay+JXzoZl+trcMUMZmzKEJz+2rihjzKm8KffxBHA1cAA4CFylqk86HZjpWyLCDXNGsqGshoLSas8HGGMGFW8GuMcAO1X1D8BG4Ly2A95m4LhqRhrRYcFWjdYYcwpvuqGeA5pFZCzwODAK14p5ZoCJiQjlqhnpvLJhP1XHG/wdzqBSUlnL8fomf4dhTKe8SRYt7tIdVwEPq+q3gREejjH91A1zR9LQ1MLSNVYvqq/sOHiU8x98j9++sc3foRjTKW+SRaOILAJuBF5x7wt1LiTjT+OHxTBndCL/+HgPzVYvynFNzS3cuayQ+qYWVn9i5c9M4PImWXwZmAv8XFU/EZFRwD+cDcv4041zs9hbfYJ3thz0dygD3h/f20lhWQ1TUmPZvP8IJxpsnosJTN7cDbVJVW9T1cXu7U9U9X7nQzP+cv7kYQyLDecJu43WUZv2HeHht7ZzWfYIvn3eeJpalI22cqEJUN5cWZhBJjQ4iOtmj+T9bRV8cui4v8MZkBqaWrhjWQFxkWHcd8VUcjNdNxiuKzns58iM6ZglC9OhRbMzCAkS/mFXF474/dvb2VJ+lPuvmkZCdBhDh4QzcmgU6/ZYsjCByetkISLRTgZiAktKbAQXTR3OM/mlAdePrtq/B94LS6t59N2dLJiZznmTh53cPyMzgfWl1f3+9zMDkzeT8k4XkU24lzwVkRwRedSbk4vIRSKyVUR2iMhdXbRbICIqInnu7TAR+auIbBSRQhGZ592vY3zpxrlZHKlr4qWCvf4OBXAliTuWFvClP6/qt1+odY3N3PlMISkx4dx9+eTPPDcjM56Ko/WUHT7hp+iM6Zw3VxYPAhfiXh1PVQuBMz0dJCLBwCPAxcBkYJGITO6gXQyuJVVXtdn9VfdrTQPOBx4QEesy62OzshKYODyGv38UGMuuLllTyvPr9/LBjkoKy/rnQPAD/9zKjoPH+OXV2cRGfPYO9NxMV71OG7cwgcirL2BVbT9Dy5t+idnADlXdpaoNwBLgig7a3YerMGFdm32Tgbfcr30QqAbyvInV+I6I8NXPj2bz/iP86V+7/BrLzopj3PvyJk4blUhkaDBLVpf4NZ6eWLO7isf//QnXn5bJmeNPXcZ+4vAYIkODWV9itblM4PEmWZSKyOmAuruHvoO7S8qDNKBtkilz7ztJRHKBDFV9hc8qBK4QkRD3vI6ZQIYXr2l87KoZaVw6bQS/WrmVNbv9M2msoamF25cUEB4axO8W5XJ5zgiWF+7jWD8qj1Hb0MR3nikkPSGSH1wyqcM2IcFBZKfHsd6uLEwA8iZZfB34Jq4v+jJgunvbE+lg38m+DHe30oPAnR20+4v7tfKBh3CVRT/lm0FEviYi+SKSX1FR4UVIprtEhP+5ehrpCZHc+vR6Ko/V93kMD765jY17a7j/qmyGxUawcHYmtQ3NLC/oP2tv3L9iCyVVtfx6QQ7R4Z0vB5ObmUDxviO2CJUJON5Myjukqter6jBVTVHVL6lqpRfnLuOzVwPpQNt/3THAVOBdEdkNzAGWi0ieqjap6rdVdbqqXgHEA9s7iO0xVc1T1bzk5FMv641vxEaE8sh1M6iqbeDbywr7dPzio52V/PG9nSyancFFU4cDkJsRz8ThMSxZ0z+6oj7YcYgnPtrDl08fxZzRQ7tsOyMznqYWpcgm55kA4+Qa3GuAcSIySkTCgIXA8tYnVbVGVZNUNUtVs4CPgfmqmi8iUa236orI+UCTqm7q3q9mfGlqWhw/uXwy72+r4NF3d/TJa9bUNnLHsgJGDY3mx5d9em+EiLBwVgYbymoC/kv1SF0j33t2A6OTo/neRRM8trdBbhOoHFuD212p9hZgJa4xjmWqWiwi94rIfA+HpwDrRGQz8N/ADV7EaRx23exM5uek8ts3tvHRTm8uLntOVfnBCxupOFrPQwunExX22a6bK3PTCQ8JCviri5+9son9NSd44Is5RIQGe2yfHBNORmKkDXKbgOPoGtyq+pqqjlfVMar6c/e+u1V1eQdt56lqvvvn3ao6QVUnqep5qmrTiAOAiPCLq6aRlRTNbUvWU3HUufGL59bt5dWN+7njgvFkp5+61lZcVCiXTBvBS+v3UdsQmAPdb285wLL8Mr5+1piTVwzemJGZwLqSw/12LokZmGwNbtMtQ8JDePT6GRyta+RbS9Y7UsZ8T+VxfvJSEaeNSuT/nTmm03aLZmdytL6JVzfs93kMvVVd28B/P7eRicNj+NZ547p1bG5GPAeO1LOvps5zY2P6iLdrcC/A1uA2bhOHx3Lv/Kl8uLOS3711yn0HvdLY3MK3lhQQHCQ8eO10goM6uqnOZVZWAmOSo1kcgHMufrK8mMPHG/jNF3MID/Hc/dTWjJGuqxC7hdYEEm9nRW8BngdeAo6JSKZzIZn+4It56Vw1I43fvb2df28/5LPz/v7tHRSUVvOLq6aRGh/ZZVvXQHcm60qq2XbgqM9i6K0VG/fzUsE+bj1nHFPT4rp9/KQRsYSHBLFuj41bmMDhzd1Qt+K6qngD10p5r/LpinlmkBIRfvaFqYxNHsLtS9dz4Ejvu0zyd1fxh7e3c/WMdC7LTvXqmKtnphMWHBQwVxeHjtXzwxeLmJYWxzfO7rwLrSuh7sl5dkeUCSTeXFl8C5igqlNUNVtVp6lqttOBmcAXFeYavzhe38yti9fT1NzS43MdqWvk9qUFpCdE8dP5p5QQ61RidBgXTBnG8+v2+n0im6rywxc2cqyuiQeuySE0uOflzGZkJrBp3xHqm2xyngkMXpX7AAL7ZnbjN+OGxfDzK6ey+pMqHnxzW4/P85OXitlfU8eD104nJqJ7S7wvmp1JzYlGXi8q7/Hr+8JLBftYWXyAOy4Yz/hhMb06V25mPA3NLRTtPeKj6IzpHW+SxS5cs6y/LyJ3tD6cDsz0H1fNSGfhrAweeWcn72zt/rrdLxXs5YX1e7ntnHHMHOn9Laat5o4eSmZilF+7ospr6rj7pSJmZMbz1c+P7vX5ZmTaILcJLN4kixJc4xVhuEp0tD6MOemn86cwcXgMdywtYF+19+sxlB2u5UcvFDFzZALf7GEff1CQsHB2Bqs+qWJXxbEenaM3VJW7nt9AQ3MLD1zT9R1c3kqJjSAt3ibnmcDhza2z96jqPcBvWn92bxtzUkRoMI9eP4OGphZuXbyeRi/GL5pblDuWFqLAg9dMJ6QXffwLZqYTEiQsXdO+mr7zlq4p5d2tFdx10URGJfluQcnczHgb5DYBw5u7oeb2dKU8M7iMTh7C/1ydzdo9h/nNyq0e2//xvZ2s3l3FvVdMIXNoVK9eOyUmgnMnpfDs2jIamno+0N5dpVW13PfKJuaOHsqNc7N8eu4ZmQnsr6ljf42tnGf8z5s/5R6iByvlmcFpfk4qX5qTyf+9v4s3Nx3otF1BaTUPvrGNy3NSuTI3rdN23bFwdiaVxxt4o4vX9aWWFuV7z24A4FcLsgnyQfdTW59OzrOuqIGouUW9ugIPFE6ulGcGqR9dOpkpqbHc+UwhZYdrT3n+eH0Tty9Zz7DYCH72hamI+OZL9sxxyaTFR/ZZccG/f7Sbj3ZV8qPLJpOR2Lsro45MHhFLWEgQ6/ZYV9RAdN8rm7jy0Q/8HYbXnFwpzwxSreMXLS3KN59ef0q30L0vb2JPVS2/vSaHuMju3SbbleAg4Zq8DP61/RClVacmKV/acfAY96/YwjkTU1g4y5lFHMNCgpiWFsf6UruyGGiamlt4sWAvRXuPUHW8wd/heMXJlfLMIDZyaDS/WpBNYWk196/YcnL/io37WZpfyjfmjeE0DwsB9cQ1s9IJEhy9umhsbuGOZQVEhgVz/1XTfHZl1JEZmfFs3FvTp+MwxnmrP6miurYRgMKy/vHHQJfJQkSCgRt6uFKeGeQunjaCm0/P4i8ffMLrRfvZX3OCu57fSHZ6HLefN96R1xwRF8m8CSk8k1/WqxnlXXn0nZ1sKKvh51+YRkpshCOv0So3M4GGphaK99m82IFkRVE54SFBiMCG0v7x/7bLZKGqzcAVfRSLGYB+cMkkctLj+O6zG/jmU+toaGrh4YW5vSqF4cmi2ZkcPFrP21u6P0HQk41lNfz+7e1cMT2VS7NH+Pz87X06Oa9//PVpPGtpUVYWl3P2hBTGJg8ZGFcWbh+IyB9E5PMiMqP14c3JReQiEdkqIjtE5K4u2i0QERWRPPd2qHs5140isllEvu/l72MCTFhIEH+4bgYCrCup5qfzJ/t0LkJHzp6QzLDYcJb4eM5FXWMz315WwNAhYdw7f6pPz92Z4XERjIiLsPkWA8j60moOHq3noqnDycmIZ0NZdb9Y6MqbFe9Od//33jb7FDinq4PcXViPAOfjGutYIyLL26+lLSIxwG3Aqja7vwiEq+o0EYkCNonIYlXd7UW8JsBkJEbx55tnsb7kMNfkOTMY3FZIcBBfnJnBo+/uYF/1CY+lzr31m5Vb2XHwGE98ZTZxUb4bmPdkRmaCXVkMICuLywkNFs6emMLRukaeXVvG3uoTpCf4/o46X/JmBvfZHTy6TBRus4EdqrpLVRuAJXTcpXUfrpX32ta4ViBaREKASKABsIpq/disrES+duYYRweD27p2VgYKLMv3zdXFRzsr+fMHn3DDnJGcOT7ZJ+f0Vm5mPHurT3DQB2XgjX+pKiuK9vO5sUnERYaSk+FaMriwH4xbeDODe5iI/FlEVri3J4vIf3hx7jRcFWtblbn3tT13LpChqu3Xx3gWOA7sx1Wb6jeqWuXFaxoDuK5mzhibxLI1pb1e+vVoXSPfeaaQkYlRfP+SiT6K0Hut63dbV1T/t2n/EUqrTnDRlOGAa9XJsOAgNvSDcQtvxiz+BqwEWlej2Qbc7sVxHf0JefJfrYgEAQ8Cd3bQbjauiX+pwCjgThE5pZSniHxNRPJFJL+iosJuPM22AAAfPUlEQVSLkMxgsmh2Jvtq6nh/e+8+G/e9son9NSd44JocosK86bn1ralpri8U64rq/1YWlRMkcP7kYYBrTG9SaiwF/WAujTfJIklVlwEtAKrahHczuMuAth3U6cC+NtsxwFRc5c93A3OA5e5B7uuA11W1UVUPAh8Aee1fQFUfU9U8Vc1LTu7brgET+M6bNIyh0WEsXtXzORdvbjrAsvwyvn7WGGaOTPRhdN4LDwlmSlqsXVkMAK8XlzN7VCJDh4Sf3Dc9PY6Ne2t6fQXsNG+SxXERGYr7qkBE5uDdYkhrgHEiMkpEwoCFwPLWJ1W1RlWTVDVLVbOAj4H5qpqPq+vpHHGJxpVItpz6EsZ0LiwkiAV56by15WCP+vsrj9Vz1/MbmDQi1rF5Id7KzUhgQ5lNzuvPdlYcY9uBYye7oFrlZMRT29DMTj+U1+8Ob5LFHbi+5MeIyAfAE8Ctng5yX4HcgqsLazOwTFWLReReEZnv4fBHgCFAEa6k81dV3eBFrMZ8xsJZmTS3KM+sLevWca4lUos4cqKJ316TQ1iIc/NCvDFjZDz1TS1sKbf7PPqr1pUcL2iXLLLTXYPcgd4V5bEDVlXXichZwARc4xBbVbXRm5Or6mvAa+323d1J23ltfj6G6/ZZY3plVFI0c0YnsnRNKf911hivK8O+WLCX14vLueviiUwaEetwlJ61Ts5bt+fwyS8X07+sLC4nJyP+lFu5RydFExMeQmFpdZ/cWt5T3v65NBvIAWYAi0TkRudCMsa3Fs3OpKSqlg93elelZl/1Ce5+qZi8kQk+WSLVF0bERTAsNpx1NsjdL5UdrmVDWQ0XTx1+ynNBQUJ2RhwbygL79llvbp19EvgNcAYwy/04ZbDZmEB14ZThxEeFstiL4oKta1Q0tygPXJPjkyVSfUFEXJPzSm2Quz9aWexaY+XCKacmC3B1RW3ef4S6xsBd/cGb+wDzgMnaH+ajG9OBiNBgrspN58mPd1N5rP4zd6K0949Ve/j3jkP8/MqpjBzqbFmS7srNjGdFUTkVR+tJjun8dzCBZ2VROROHx3Ra6iYnPZ6mFmXz/iMn59UEGm+6oYqAjtOhMf3EotkZNDYrz6/b22mbXRXH+MVrmzlrfDLXzc7sw+i882lRQbu66E8qjtazZk9Vp1cVANNPzuQO3G7GTpOFiLwsIsuBJFy1mVaKyPLWR9+FaEzvjRsWw8yRCSxeU9Jh0bam5hbuWFZIeEgwv1qQ3WdlSbpjalococFi4xb9zD83laMKF0/rPFkMj4sgJSacwgAet+iqG+o3fRaFMX1g0exMvvNMIas/qTpl4aU/vreTgtJqfr8ol2EOr1HRUxGhwUweYZPz+pvXi8rJGhrFhGExXbbLyYgP6HLlnV5ZqOp7rQ9cE+Ji3I/N7n3G9CuXThtBTETIKaXLi/bW8NCb27ksewSX56R2cnRgyM1MYENZtWMLOxnfqqlt5KOdlVw4dbjHq9Wc9Dh2VRyn5oRXMxP6nDd3Q10DrMY17+EaYJWILHA6MGN8LTIsmC9MT+PVjfuprnWte1zX2MydywpJjA7jviv6Zo2K3pgxMoG6xha2lB/1dyjGC29uPkBTi3LxVM8LZbVWoN0YoF1R3gxw/xCYpao3qeqNuOZc/NjZsIxxxqLZmTQ0tfDCetdA94NvbGPrgaP8ckE2CdFhfo7Os1z3F4p1RfUPrxeXMyIuguy0OI9ts9Pcg9wB2hXlTbIIchfza1Xp5XHGBJzJqbHkpMexZHUpqz+p4rF/7eK60zI5e0KKv0PzSnpCJMkx4VaBth84Xt/E+9squHDKcK8qB8RFhTIqKTpg74jy5kv/dfedUDeLyM3Aq8AKZ8MyxjkLZ2ey9cBRvvZkPhkJUfzwkkn+DslrIkJuRrxdWfQD722roL6ppctbZtvLSQ/cmdzerJT3XeD/gGxcJT8eU9XvOR2YMU65PCeVqLBgak408ttrcogO7/s1KnpjxsgE9lTWcuhYvb9D6VJdYzOlVbX+DsNvVhSVMzQ6jNmjvC9tn5MRT/mROsprAm9VxE7/lYjIWGCYqn6gqs8Dz7v3nykiY1R1Z18FaYwvDQkP4b4rptKiSl6Wf9ao6I3WyXkFJdWc515Ex99qTjSyad8RivfVuP97hB0Vx2huURZ/dQ5zxwz1fJIBpK6xmbc3H+DynNRulYxpLRJZWFbN8LjAmgvd1Z9UDwE/6GB/rfu5yx2JyJg+cPXMdH+H0GPT0uIICRLWlRzu82Shqhw4Uv+ZpFC8v4bSqhMn26TEhDMlNZbzJqfw+L8+4Z+bygddsvhw5yGONzRzYQeFA7syJTWWkCBhQ1l1t7qv+kJXySKrozUkVDVfRLIci8gY06XIsGAmjYh1fJC7pUXZXXnclRDaXDVUHm842SZraBTZafEsnJXJlNRYpqTGfaZuVdHeI7y3tWLQ/Wm5YmM5MeEhfG5MUreOiwgNZuKIGApLA2/coqtk0dU01sgunjPGOGxGZjzPrC2jqbmFkGDf3pxYeayeby8rJH93FbUNriqoocHCuJQYzpmY4koKaXFMGhHLEA/jPWdPSOanL29iT+XxgCvM6JSm5hbe2HyAcyel9GjRrOz0eF4u3EdLi3q9/kpf6Or/9BoR+aqq/qntThH5D2CtNycXkYuAh4Fg4HFVvb+TdguAZ3DN58gXkeuB77Zpkg3MUNUCb17XmIEuNzOBv3+0h60HjjIl1fM9/N5SVb777AY+3lnJotkZTEmNY3JqLOOHxfToi2/ehBR4eRPvbq3gptMHR7JY/UkV1bWNXNTNLqhW09PjeXpVCbsrjzM6eYiPo+u5rpLF7cAL7i/u1uSQB4QBV3o6sYgE41oe9XygDFfyWa6qm9q1iwFuA1a17lPVp4Cn3M9PA16yRGHMpz6tQFvt02Txlw928/aWg9wzfwo3nZ7V6/NlJUUzKimad7Ye9Mn5+oPXi8uJCA3izPHJPTo+O8P1/7OwrDqgkkVXtaEOqOrpwD3AbvfjHlWdq6rlXpx7NrBDVXepagOwBLiig3b3Ab8COrtXbBGw2IvXM2bQyEiMJGlImE/nW2wsq+H+FZs5f/Iwbpw70mfnPWt8Mh/trAzohX18paVFeb2onHnjU4gK69kt2eNSYogKCw64cQtv5lm8o6q/dz/e7sa504C2FdvK3PtOEpFcIENVX+niPNdiycKYzxARpmck+GyQ+1h9E7cuXkfSkHB+7eMS7WdPTKG+qYWPdnm3rG1/tr60moNH63vcBQUQHCRMTYsLuLIfTpbt6OjTdnIhAREJAh4E7uz0BCKnAbWqWtTJ818TkXwRya+oqOhtvMb0KzNGxvPJoeMcbnN3Uk+oKj96YSMlVbU8vDCX+Cjf1sg6bVQiEaFBrruiBriVxeWEBgtnT+xd+Zic9DiK9x2hoSlwqgs7mSzKgIw22+nAvjbbMcBU4F0R2Q3MAZaLSNv1vRfSxVWFqj6mqnmqmpec3LP+QWP6q9wM97hFL9flfm7dXl4s2Mft543v1mxjb0WEBnP6mCTe2XrQc+N+TNXVBXX6mCTiIkN7da6cjHgamlrYdiBwqgs7mSzWAONEZJSIhOH64j+5wp6q1qhqkqpmqWoW8DEwX1Xz4eSVxxdxjXUYY9rJyYgjOEhYt6fn3RU7K45x90tFzBmdyDfPHuvD6D5r3oRk9lTW8smh4469hr9t2n+EkqpaLu5FF1SrHPdM7oIAKiroWLJQ1SbgFmAlsBlYpqrFInKviMz34hRnAmWqusupGI3pz6LCQpg4PKbHVxZ1jc3c+vR6wkOCeOja3G6VpeiueeNd3TLvbBm4Vxcri8oJEnwyqz49IZLE6LCAqkDraAU1VX0NeK3dvrs7aTuv3fa7uLqmjDGdyM2M54V1e2lu0W5/2d+/Ygub9h/hLzfnMTzO2aVkM4dGMTo5mne3VfCVM0Y5+lr+8npxObOyEkkaEu65sQciEnAVaG1dCmP6sRmZCRxvaGb7we71bb+x6QB/+3A3X/ncKM6Z2Df1pc6ekMLHuyo50TDwbqHdWXGMbQeO+aQLqlVORjzbDh7lWH2Tz87ZG5YsjOnHWifndWfcYn/NCb77bCFT02L574snOBXaKeZNSKahqYWPdh3qs9fsK68XuaaeXeDD4n856fGoutaIDwSWLIzpx0YOjSIx2vvJeU3NLXxrcQGNTS38ftEMwkOCHY7wU7NHJRIZGsw7WwbeLbQri8vJyYgnNd53ZfOy010zuTcEyHwLSxbG9GOtK+et9zJZ/P7tHazeXcXPrpzKqKS+rdUUHhLM58YO5Z2tB1FVzwf0E3urT7ChrIaLfFxSfOiQcDISIwNmJrclC2P6udzMeHZWHKe6tuvJeR/vquT3b2/n6hnpXJnrn/U85k1IoezwCXZWDJxbaFu7oHoza7sz2enxATOT25KFMf3cyaKCXdxmWXW8gduXFJA1NJp7r5jSV6GdYt4E1+TZd/0wQe/1ov2c/j9v8Ux+qU+vbFYWlTNxeIwjV2rT0+MpO3wiIJbQtWRhTD+XnRFPkNBpnShV5bvPFFJ1vIHfLcr165rj6QlRjEsZwrt+KP3x6Ls7KT9Sx3ef3cCNf1ntk/XBK47Ws2ZPlWOr2gXSuIUlC2P6uSHhIYwfFtPpuMVfP9jNW1sO8oNLJjI1zXflzHtq3oRkVn9SxfE+vCV0Q1k1G8pq+PFlk7nvC1NZX1LNhQ+9z1/+/QnNLT2/yvjnpnJU4eJpziSLqWlxBAkBMW5hycKYAWDGyAQKSqppaffFV7S3hvtXbOG8ScMCZj2Jsyek0NDcwoc7+64K7dOrSogMDebqmencMGck//z2mZw2KpF7X9nEgj9+yPYe1mB6vaicrKFRTBgW4+OIXaLdfwgEwriFJQtjBoAZmQkcrW9iR8Wxk/tcZcfXkxgd5vOy472Rl5VIdFhwnxUWPFLXyEsF+5ifk0pshKvAX2p8JH+5eRYPL5zO7kPHufR3/+Z3b23vVpXXmtpGPtpZyYVThzv63manx1FYWu33O8gsWRgzAORmugrPrdvzaVfU3S8VsafyOA8vnE5CtG/LjvdGWEgQnxubxHtbK/rkC/Cl9Xs50djM9XMyP7NfRLhiehpv3nEWF00dzm/f2Mb8P/zb63pMb205QFOL+vyW2fZyMuI5XNtI2eETjr6OJ5YsjBkARidFEx8VenKQ+7m1ZTy/bi+3nTuO00YP9XN0p5o3IYW91SfYfvCY58a9oKo8taqEqWmxZLsrubY3dEg4v1uUy+M35lFd28iVj37AL17b7LEsyYqickbERZysEOuUQKlAa8nCmAGgdXLeupLD7Ko4xo9fKuK0UYnces44f4fWob66hXZdyWG2lB/l+tM8LxN73uRh/POOM1k4O5PH3t/FRQ+/z4c7Oy5Ncry+ife3VXDhlOEEOVitF2DC8BjCQ4L8XoHWkoUxA0RuZgLbDx7jv/6xzlV2fOF0R8uO90ZqfCQThsU4XvrjqY9LGBIewvycVK/ax0aE8osrp7H4q3MQ4Lo/reL7z2+g5kTjZ9q9t62C+qYWx26ZbSs0OIgpqbF+r0BrycKYAaJ1ct7WA0f59YIcRsT5rk6RE+ZNTCZ/TxVH6xo9N+6B6toGXtm4nytz07o9t2TumKGs+NaZ/L8zR7N0TSkXPPgeb2w6cPL514vKSYwOY1ZWgq/D7lBORjwb99bQ1Oy/ZVYtWRgzQORkxBEdFsx/nDHKJwvwOG3e+BQam5UPdjhzC+2za8toaGrhutMyPTfuQGRYMN+/ZBIvfvNzJESF8dUn8rnl6XXsqz7B21sOcsHkYYQE981XaE56PCcamz9zt1tfc/Q3FZGLRGSriOwQkbu6aLdARLTt+tsiki0iH4lIsYhsFBFnV2cxpp+LiQjlw++fy48uneTvULySl5XAkPAQ3tvm+3ELVeXpVSXMyIxn0ojYXp0rOz2el289g+9cMJ5/Fh9g3m/e5Vh9Exc6UAuqMzkZrkFuf45bOJYsRCQYeAS4GJgMLBKRyR20iwFuA1a12RcC/AP4uqpOAeYBzlyrGjOAxEWGBsx8Ck9Cg4M4Y2wS72zx/S20H+2qZNeh414NbHsjNDiIW84Zx2vfOoNpaXGMiIvg9DF9d5dZ1tAoYiNCKPDjTG4nryxmAztUdZeqNgBLgCs6aHcf8Cugrs2+C4ANqloIoKqVqjrwltcyZpA7e2Iy5Ufq2NrDGdSdeWpVCXGRoVyaPcKn5x2bEsOzX5/L+987u0/XAhERcjLi/VojyslkkQaUttkuc+87SURygQxVfaXdseMBFZGVIrJORL7nYJzGGD85a3wKgE/viqo4Ws8/i8tZMDOdiFDff6GLCKF9NFbRVk56PFvKj1LX6J+/m538jTu6Fj55rSkiQcCDwJ0dtAsBzgCud//3ShE595QXEPmaiOSLSH5FxcBbfcuYgW54XASTRsT6dL7FM2tLaWxWFs3u2cB2oMpOj6O5RSne55+uKCeTRRmQ0WY7HdjXZjsGmAq8KyK7gTnAcvcgdxnwnqoeUtVa4DVgRvsXUNXHVDVPVfOSk5Md+jWMMU6aNyGZ/D2HOeKDW2hbWlwD23NGJzI2ZYgPogsc008Ocg+8ZLEGGCcio0QkDFgILG99UlVrVDVJVbNUNQv4GJivqvnASiBbRKLcg91nAZscjNUY4ydnT0ihuUX5YHvHs6W74/3tFZQdPuGzge1AkhIbwYi4CL9VoHUsWahqE3ALri/+zcAyVS0WkXtFZL6HYw8Dv8WVcAqAdar6qlOxGmP8Z0ZmPDERIT6pQvv0qhKGRof1ycxqf2itQOsPji6Zpaqv4epCarvv7k7azmu3/Q9ct88aYwawkOAgzhyXzLvuKrQ9vfV3f80J3tpykK9+fjRhIQNzvnFORjwriw9QXdtAfFTfVhIemO+oMaZfOWtCMgeP1rNp/5Een2PpmlKaW5TrBtjAdlvT3RVo/VEnypKFMcbv5o1vrULbs7sam5pbWLK6lDPHJ5M5NMqXoQWUqX5ck9uShTHG71JiI5iS2vNbaN/ecpDyI3Vc38M6UP1FbEQoY5Kj/TKT25KFMSYgnD0hhXUl1dTUdv8W2qdXlzAsNpxzJ6Y4EFlgycmIp7Cs75dZtWRhjAkI8yYk09yi/GtH97qiSqtqeW9bBdfOyuyzKrD+lJMeT8XResqP1Hlu7EMD/501xvQL0zPiiYsM7fa4xeLVJQiwcFaGx7YDgb8q0FqyMMYEhJDgID4/Lol3t1bQ0uJdF0tDUwvL8ks5Z+IwUuMDe7EnX5k0IobQYOnzcQtLFsaYgHH2hBQOHfP+Fto3Nh3g0LEGrp8zsAe22woPCWbSiNg+vyPKkoUxJmCc6b6F9p0t3t0V9dSqPaTFR3LmuMFVGy4nPZ6NZTVeX4H5giULY0zASI4JJzs9jne3eR632FlxjA93VnLdaZkEB/WPBZ98JTs9jqP1Tew6dLzPXtOShTEmoMwbn8z6ksNU1zZ02W7xqhJCgoQv5qX3UWSBY7ofBrktWRhjAsq8iSm0KLzfRRXausZmnl1XxoVThpMSE9GH0QWG0clDGBIe0qcVaC1ZGGMCSk56PAlRobzbxbjFiqL9VNc2DvgZ250JDhKmpsVS2Ic1oixZGGMCSnCQcOb4ZN7b1vkttE99XMKopGjmjhnax9EFjpyMeDbvO0J9U98ss2rJwhgTcOZNSKbyeAMb9576l/OW8iPk7znMdbMze1zOfCCYnh5PQ3MLW/Yf7ZPXs2RhjAk4Z45LRqTjKrRPryohLCSIq2cOvoHttrIzWsuV9824haPJQkQuEpGtIrJDRO7qot0CEVH3+tuISJaInBCRAvfjj07GaYwJLEOHhJOdHn/K6nm1DU28sG4vl04bQWJ03y7+E2hS4yJIGhLeZzO5HUsWIhIMPAJcDEwGFonI5A7axQC3AavaPbVTVae7H193Kk5jTGA6e0IyhWXVVB3/9Bbalwv3cbS+iesG6cB2WyLC9Iy4Prsjyskri9nADlXdpaoNwBLgig7a3Qf8CujbEorGmIA2b0IKqvB+mwl6T60qYfywIeSNTPBjZIEjOz2enRXHOFrX/bLu3eVkskgDSttsl7n3nSQiuUCGqr7SwfGjRGS9iLwnIp93ME5jTADKTotjaHTYyQWRNpbVsKGshutPGzmoB7bbysmIR5UObwTwNSeTRUf/N0/eByciQcCDwJ0dtNsPZKpqLnAH8LSIxJ7yAiJfE5F8EcmvqOjZcozGmMAU1OYW2uYW5enVe4gMDebKGWmeDx4kstNal1nt38miDGhbYD4d2NdmOwaYCrwrIruBOcByEclT1XpVrQRQ1bXATmB8+xdQ1cdUNU9V85KTB1chMWMGg3kTkjlc28gHOw7xUsE+Ls8ZQWxEqL/DChgJ0WGMHBrVJ2U/nEwWa4BxIjJKRMKAhcDy1idVtUZVk1Q1S1WzgI+B+aqaLyLJ7gFyRGQ0MA7Y5WCsxpgAdOa4ZIIEfvjiRmobmrn+tJH+DingzB09tE8KKYY4dWJVbRKRW4CVQDDwF1UtFpF7gXxVXd7F4WcC94pIE9AMfF1Vq5yK1RgTmBKiw5ieEc+6kmqmpsWSnR7n75ACzv1XZ/fJ6ziWLABU9TXgtXb77u6k7bw2Pz8HPOdkbMaY/mHehBTWlVTbwLafOZosjDGmtxbOyqDmRCNfmG4D2/5kycIYE9BSYiP48WWnzOc1fcxqQxljjPHIkoUxxhiPLFkYY4zxyJKFMcYYjyxZGGOM8ciShTHGGI8sWRhjjPHIkoUxxhiPRFU9t+oHRKQC2OPvOHwkCTjk7yACmL0/XbP3p3P23pxqpKp6LNs9YJLFQCIi+aqa5+84ApW9P12z96dz9t70nHVDGWOM8ciShTHGGI8sWQSmx/wdQICz96dr9v50zt6bHrIxC2OMMR7ZlYUxxhiPLFn4mYhkiMg7IrJZRIpF5Fvu/Yki8oaIbHf/N8HfsfqLiASLyHoRecW9PUpEVrnfm6XuNd4HJRGJF5FnRWSL+zM01z47nxKRb7v/XRWJyGIRibDPT89YsvC/JuBOVZ0EzAG+KSKTgbuAt1R1HPCWe3uw+hawuc32L4EH3e/NYeA//BJVYHgYeF1VJwI5uN4n++wAIpIG3AbkqepUIBhYiH1+esSShZ+p6n5VXef++Siuf+xpwBXA393N/g58wT8R+peIpAOXAo+7twU4B3jW3WQwvzexwJnAnwFUtUFVq7HPTlshQKSIhABRwH7s89MjliwCiIhkAbnAKmCYqu4HV0IBUvwXmV89BHwPaHFvDwWqVbXJvV2GK7kORqOBCuCv7m66x0UkGvvsAKCqe4HfACW4kkQNsBb7/PSIJYsAISJDgOeA21X1iL/jCQQichlwUFXXtt3dQdPBektfCDAD+F9VzQWOM0i7nDriHqu5AhgFpALRwMUdNB2sn59usWQRAEQkFFeieEpVn3fvPiAiI9zPjwAO+is+P/ocMF9EdgNLcHUfPATEu7sVANKBff4Jz+/KgDJVXeXefhZX8rDPjst5wCeqWqGqjcDzwOnY56dHLFn4mbsP/s/AZlX9bZunlgM3uX++CXipr2PzN1X9vqqmq2oWroHJt1X1euAdYIG72aB8bwBUtRwoFZEJ7l3nApuwz06rEmCOiES5/521vj/2+ekBm5TnZyJyBvAvYCOf9sv/ANe4xTIgE9eH/ouqWuWXIAOAiMwDvqOql4nIaFxXGonAeuBLqlrvz/j8RUSm4xr8DwN2AV/G9UegfXYAEbkHuBbXXYfrgf/ENUZhn59usmRhjDHGI+uGMsYY45ElC2OMMR5ZsjDGGOORJQtjjDEeWbIwxhjjkSULMyiJiIrIA222vyMiP/Xxa3xZRArcjwYR2ej++f4enCtDRJb6Mj5jusNunTWDkojU4aoXNEtVD4nId4AhqvpTh15vN67qp4ecOL8xTrMrCzNYNeFaYvPb7Z8Qkb+JyII228fc/50nIu+JyDIR2SYi94vI9SKy2n3VMMbbFxeRJBFZLiIbRORDEZnq3v8zEfm7e42T7SLyFff+sSJS4P45REQedK/RsEFEvuHe/2sR2eTe98vevDnGtBfiuYkxA9YjwAYR+VU3jskBJgFVuGZMP66qs92LVt0K3O7lee4DVqnqfBG5APgbkOd+bhquGkaxwDoRebXdsf+FqzBejqo2uxc7GgZcAkxRVRWR+G78TsZ4ZFcWZtByV/d9AtcCOd5a416DpB7YCfzTvX8jkNWN85wBPOmO459Aqru8OMCLqlqnqgeB94FZ7Y49D/ijqja7j6/ClbxagD+JyJW4KtAa4zOWLMxg9xCuldKi2+xrwv1vw12Aru2ym21rCLW02W6he1fq7Uutt91uP5DYflva73NXVc0DXgSuBtpfjRjTK5YszKDm/qt8GZ9dWnM3MNP98xVAqAMv/T5wPYCInIer1Hjr1cAXRCRcRJKAzwP57Y79J/BfIhLsPj5RRGKAWFV9Bdc4TK4DMZtBzMYsjIEHgFvabP8JeElEVuNaw9qJLp27ca1wtwE4hqtabKs1wAogA/iJqh5wJ4NW/weMwzXe0gT8L/AK8LyIhOP6I/AOB2I2g5jdOmtMABGRnwGHVPUhf8diTFvWDWWMMcYju7IwxhjjkV1ZGGOM8ciShTHGGI8sWRhjjPHIkoUxxhiPLFkYY4zxyJKFMcYYj/4/OAuj5nLH+l0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph of number of topics vs coherence \n",
    "limit=100; start=10; step=5;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5085940577923722,\n",
       " 0.5268261101848211,\n",
       " 0.5170557519650683,\n",
       " 0.5076504914960591,\n",
       " 0.4905865017610599,\n",
       " 0.4811363186903156,\n",
       " 0.49117589638704723,\n",
       " 0.4731400427598802,\n",
       " 0.48352880760582295,\n",
       " 0.49405675153989365,\n",
       " 0.46180709007441967,\n",
       " 0.47153943278608235,\n",
       " 0.47290154854168903,\n",
       " 0.448053443835022,\n",
       " 0.46565254835150577,\n",
       " 0.4610292150405999,\n",
       " 0.4832309098903623,\n",
       " 0.4491806070073582]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model15 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=15, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x1a25606748>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(model_list[1].print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = model15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_index = similarities.MatrixSimilarity(lda[corpus],num_features=len(id2word), num_best = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_recommender (query):\n",
    "    recs = []\n",
    "    i = df.index[df['id'] == query].tolist()[0]\n",
    "    words = data_lemmatized[i]\n",
    "    query_vector = id2word.doc2bow(words)\n",
    "    sims = lda_index[query_vector]\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Album Review: “Frozen Throne”—Groundislava\\n 0.11934711039066315',\n",
      " 'How Astroworld Broke Hip Hop’s Weak Streak 0.11912423372268677',\n",
      " 'Album Review: \"Dream Your Life Away\"—Vance Joy 0.11858555674552917',\n",
      " \"Listen to This: 'Atlanta' Soundtrack Highlights 0.11853858083486557\",\n",
      " 'REVIEW: Avey Tare, Down There 0.11806224286556244',\n",
      " \"Amy Winehouse and Nas Duet on Salaam Remi's New Song 0.11794278025627136\",\n",
      " 'Review: \"Battle Born” — The Killers 0.1177503690123558',\n",
      " 'Album Review: \"Sweet Talker\"—Jessie J 0.11704496294260025',\n",
      " 'Toro Y Moi — \"Anything in Return\"  0.11701808124780655',\n",
      " 'Review: Kanye West, “My Beautiful Dark Twisted\\xa0Fantasy” '\n",
      " '0.11691488325595856']\n"
     ]
    }
   ],
   "source": [
    "see_recs(lda_recommender(37013)) #oscars article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vote for your 2014 Senior Superlatives 0.2072090059518814',\n",
      " \"Valentine's Day DIY Poll 0.18919692933559418\",\n",
      " 'Vote For Senior Superlatives 2K16 0.16972923278808594',\n",
      " 'Vote for Best of Penn: 2012 0.16848856210708618',\n",
      " 'Vote for your Tweet of the Week: 2/14-2/21 0.16098614037036896',\n",
      " 'Vote for Your Tweet of the Week: 11/8 0.1609855592250824',\n",
      " 'Vote for Your Tweet of the Week: 2/7 - 2/14  0.1609855592250824',\n",
      " 'Vote for Your Tweet of the Week: 1/26 0.16098244488239288',\n",
      " 'Vote for your Tweet of the Week 11/15-11/22 0.1609824001789093',\n",
      " 'Vote For Your Tweet of the Week: 1/31-2/7 0.16098226606845856']\n"
     ]
    }
   ],
   "source": [
    "see_recs(lda_recommender(37011)) #France Quinlan comes full circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
